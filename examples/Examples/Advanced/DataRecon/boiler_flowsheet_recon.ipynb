{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reconciliation of a Supercritical Coal-Fired Boiler, Flowsheet  Example\n",
    "\n",
    "This notebook demonstrates data reconciliation with a flowsheet heat exchanger network, the boiler subflowsheet consist of an economizer, water wall, primary superheater, platen superheater, finishing superheater, and reheater.  Data for this example was generated by adding noise to supercritical power plant simulations.\n",
    "\n",
    "### Why reconcile data?\n",
    "\n",
    "Data reconciliation uses mass and energy balances along with redundant measurements to improve data quality by:\n",
    "\n",
    "1. reducing measurement error,\n",
    "2. ensuring measurements satisfy mass and energy balances, and\n",
    "3. filling in unmeasured quantities.\n",
    "\n",
    "Data reconciliation is used to refine process data before parameter estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Read Plant Data\n",
    "\n",
    "The first step is to read in process data.  In this case, data was simulated by adding measurement error to supercritical steam cycle simulation results.  IDAES includes functions to read process data, convert units to match the models, and map data to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDAES module with functions to read, analyze and visualize plant data\n",
    "import idaes.dmf.model_data as da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process data is contained in two csv files, a data file and a metadata file.  The data file where the first column is row indexes and the first row is process measurement tags.  The index column has an entry for each data row, and is often a timestamp.  The metadata file contains information about the tags including units of measurement, description, and model mapping information.\n",
    "\n",
    "Once the process data is read in, the data is assigned to bins based on the value in a given column, in this case gross power. Dividing the data into bins allows rough estimation of measurement uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data and column metadata\n",
    "df, df_meta = da.read_data(\"plant_data.csv\", \"plant_data_meta.csv\")\n",
    "# Add bin information where the data is sorted into 5 MW bins based on the \"GROSS_POWER\" column\n",
    "bin_count = da.bin_data(df, bin_by=\"POWER_GROSS\", bin_no=\"bin_no\", bin_nom=\"bin_power\", bin_size=5e6)\n",
    "# Calculate the standard deviation by bin for each column\n",
    "bin_stdev = da.bin_stdev(df, bin_no=\"bin_no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be useful to visualize the measurement data and estimated uncertainty.  The following creates box and whisker plots for each tag based on the data bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pdf book of plots that shows box and whisker plots for each column by bin\n",
    "import os\n",
    "if not os.path.isfile(\"data_plot_book.pdf\"):\n",
    "    da.data_plot_book(df, file=\"data_plot_book.pdf\", bin_nom=\"bin_power\", xlabel=\"gross power (W)\", metadata=df_meta)\n",
    "# There should now be a data_plot_book.pdf file in this directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Boiler Flowsheet Setup\n",
    "\n",
    "Now that we have the plant data, we need to create the flowsheet model that we can use for data reconciliation. Although we need a model that has just mass and energy balances and feasibility constraints for the data reconciliation problem, we start with the boiler flowsheet model here.  Using the same model for data reconciliation, parameter estimation, validation, and simulation reduces the work required to move between steps in the workflow.\n",
    "\n",
    "Once the full flowsheet model is created, constraints that are not needed for data reconciliation can be deactivated.\n",
    "\n",
    "### 2.1 Case Study:\n",
    "In a supercritical coal-fired power plant, the boiler sub-system consists of multiple heat exchangers transferring heat from the combustion side to the water/steam side. The boiler system for this work (Figure 1) is based on a 550 MWe supercritical power plant. Note that water wall and platen superheater are modeled as a heater, while the rest of the units correspond to the shell and tube heat exchangers.\n",
    "Note that boiler flowsheet block diagram shows the available measurements from plant data. *for demonstration purposes \"plant data\" has been trained at different operating loads and with noise.\n",
    "\n",
    "<img src=\"boiler_flowsheet.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pyomo and idaes libraries\n",
    "# import idaes flowsheet object\n",
    "from idaes.core import FlowsheetBlock\n",
    "# import flue gas property package\n",
    "from idaes.power_generation.properties.flue_gas_ideal import FlueGasParameterBlock\n",
    "from idaes.core.util import model_serializer as ms\n",
    "# import utility to report degrees of freedom\n",
    "from idaes.core.util.model_statistics import degrees_of_freedom\n",
    "# import water/steam property package and functions to calculate enthalpy\n",
    "from idaes.generic_models.properties import iapws95\n",
    "# import unit models from power generation library\n",
    "from idaes.power_generation.unit_models.boiler_heat_exchanger import (\n",
    "    BoilerHeatExchanger, \n",
    "    TubeArrangement, \n",
    "    DeltaTMethod\n",
    ")\n",
    "import pyomo.environ as pyo\n",
    "# import methods to build the flowsheet and deactivate performance constraints\n",
    "import boiler_data_rec as flowsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Flowsheet Setup\n",
    "The \"boiler_flowsheet\" method imports all the unit models in the boiler heat exchanger network, builds the flowsheet, builds the flowsheet connectivity, and initializes the flowsheet.\n",
    "\n",
    "The final solve corresponds to a simulation case, with the following inputs (relative to a ~650 MW case):\n",
    "- Econommizer (water): F, h, P\n",
    "- Reheater Inlet (Cold Reheat steam): F, h, P\n",
    "- Coal flowrate (kg/s) and stoichiometric ratio (unitless)\n",
    "- Dimensions of all units (tube diameter, # tubes, hx area, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boiler flowsheet, the main unit models are: \n",
    "# heat exchanger model: economizer, primary super heater, finishing superheater, and reheater\n",
    "# heater model: water wall and platen superheater\n",
    "\n",
    "m = flowsheet.boiler_flowsheet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Simplify to Mass and Energy Balances\n",
    "\n",
    "For data reconciliation, the flowsheet model should be reduced to mass and energy balances and potentially limited performance constraints to keep the results feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deactivate constraints for heat transfer (for all heat exchanger units)\n",
    "# for example to deactivate heat trasnfer calculation in the economizer we include:\n",
    "# m.fs.ECON.overall_heat_transfer_coefficient_eqn.deactivate()\n",
    "\n",
    "# The method \"deactivate_performance_constraints\" deactivates the equations for all \n",
    "# heat exchangers in this flowsheet (Economizer, Primary Superheater, \n",
    "#                                    Finishing Superheater, Reheater)\n",
    "flowsheet.deactivate_performance_constraints(m)\n",
    "\n",
    "# Now the model has 12 DoF \n",
    "# deltaP shell and tube, and U - overall heat transfer coefficient in 4 hx models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Map Data to the Model\n",
    "\n",
    "Although the model mapping can be added to the tag metadata file, here we just add the mapping information to the tag metadata after reading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water/Steam Measurements ----------------------------------------------- #\n",
    "# Economizer inputs\n",
    "df_meta[\"BFW_F\"][\"reference_string\"] = \"m.fs.ECON.side_1.properties_in[:].flow_mol\"\n",
    "df_meta[\"BFW_T\"][\"reference_string\"] = \"m.fs.ECON.side_1.properties_in[:].temperature\"\n",
    "df_meta[\"BFW_P\"][\"reference_string\"] = \"m.fs.ECON.side_1.properties_in[:].pressure\"\n",
    "\n",
    "# Economizer outputs\n",
    "df_meta[\"ECON_OUT_T\"][\"reference_string\"] = \"m.fs.ECON.side_1.properties_out[:].temperature\"\n",
    "df_meta[\"ECON_OUT_P\"][\"reference_string\"] = \"m.fs.ECON.side_1.properties_out[:].pressure\"\n",
    "\n",
    "# Reheater inputs \n",
    "df_meta['RHT_COLD_T'][\"reference_string\"] = \"m.fs.RH.side_1.properties_in[:].temperature\"\n",
    "df_meta['RHT_COLD_P'][\"reference_string\"] = \"m.fs.RH.side_1.properties_in[:].pressure\"\n",
    "df_meta['RHT_COLD_F'][\"reference_string\"] = \"m.fs.RH.side_1.properties_in[:].flow_mol\"\n",
    "\n",
    "# Reheater outputs \n",
    "df_meta['RHT_HOT_T'][\"reference_string\"] = \"m.fs.RH.side_1.properties_out[:].temperature\"\n",
    "df_meta['RHT_HOT_P'][\"reference_string\"] = \"m.fs.RH.side_1.properties_out[:].pressure\"\n",
    "\n",
    "# primary SH outlet\n",
    "df_meta['PlatenSH_IN_P'][\"reference_string\"] = \"m.fs.PrSH.side_1.properties_out[:].pressure\"\n",
    "\n",
    "# Platen SH outlet inlet to Finishing SH\n",
    "df_meta['FSH_In_P'][\"reference_string\"] = \"m.fs.PrSH.side_1.properties_in[:].pressure\"\n",
    "\n",
    "# Finishing SH outlet ----------------------------------------------------- #\n",
    "# Main Steam \n",
    "df_meta['MS_T'][\"reference_string\"] = \"m.fs.ATMP1.mixed_state[:].temperature\"\n",
    "df_meta['MS_P'][\"reference_string\"] = \"m.fs.ATMP1.mixed_state[:].pressure\"\n",
    "df_meta['MS_F'][\"reference_string\"] = \"m.fs.ATMP1.mixed_state[:].flow_mol\"\n",
    "\n",
    "# Flue Gas measurements\n",
    "# Finishing inputs\n",
    "df_meta['FG_2_FSH_Fm'][\"reference_string\"] = \"m.fs.FSH.side_2.properties_in[:].flow_mass\"\n",
    "df_meta['FG_2_FSH_T'][\"reference_string\"] = \"m.fs.FSH.side_2.properties_in[:].temperature\"\n",
    "df_meta['FG_2_FSH_P'][\"reference_string\"] = \"m.fs.FSH.side_2.properties_in[:].pressure\"\n",
    "\n",
    "# Reheater inputs\n",
    "df_meta['FG_2_RH_T'][\"reference_string\"] = \"m.fs.RH.side_2.properties_in[:].temperature\"\n",
    "df_meta['FG_2_RH_P'][\"reference_string\"] = \"m.fs.RH.side_2.properties_in[:].pressure\"\n",
    "\n",
    "# Primary SH inputs\n",
    "df_meta['FG_2_PrSH_Fm'][\"reference_string\"] = \"m.fs.PrSH.side_2.properties_in[:].flow_mass\"\n",
    "df_meta['FG_2_PrSH_T'][\"reference_string\"] = \"m.fs.PrSH.side_2.properties_in[:].temperature\"\n",
    "df_meta['FG_2_PrSH_P'][\"reference_string\"] = \"m.fs.PrSH.side_2.properties_in[:].pressure\"\n",
    "\n",
    "# Economizer inputs\n",
    "df_meta[\"FG_2_ECON_P\"][\"reference_string\"] = \"m.fs.ECON.side_2.properties_in[:].pressure\"\n",
    "\n",
    "# Economizer outputs\n",
    "df_meta[\"FG_2_AIRPH_T\"][\"reference_string\"] = \"m.fs.ECON.side_2.properties_out[:].temperature\"\n",
    "df_meta[\"FG_2_AIRPH_P\"][\"reference_string\"] = \"m.fs.ECON.side_2.properties_out[:].pressure\"\n",
    "\n",
    "# --------------------------------------------------------------------------------------- #\n",
    "# Other inputs available in the data set (but not used as measurements in this study)\n",
    "df_meta[\"ECON_OUT_F\"][\"reference_string\"] = \"m.fs.ECON.side_1.properties_out[:].flow_mol\"\n",
    "df_meta['RHT_HOT_F'][\"reference_string\"] = \"m.fs.RH.side_1.properties_out[:].flow_mol\"\n",
    "df_meta['FG_2_RH_Fm'][\"reference_string\"] = \"m.fs.RH.side_2.properties_in[:].flow_mass\"\n",
    "df_meta[\"FG_2_ECON_Fm\"][\"reference_string\"] = \"m.fs.ECON.side_2.properties_in[:].flow_mass\"\n",
    "df_meta[\"FG_2_ECON_T\"][\"reference_string\"] = \"m.fs.ECON.side_2.properties_in[:].temperature\"\n",
    "df_meta[\"FG_2_AIRPH_Fm\"][\"reference_string\"] = \"m.fs.ECON.side_2.properties_out[:].flow_mass\"\n",
    "\n",
    "df_meta['FG_RH_2_Mix_Fm'][\"reference_string\"] = \"m.fs.RH.side_2.properties_out[:].flow_mass\"\n",
    "df_meta['FG_RH_2_Mix_T'][\"reference_string\"] = \"m.fs.RH.side_2.properties_out[:].temperature\"\n",
    "df_meta['FG_RH_2_Mix_P'][\"reference_string\"] = \"m.fs.RH.side_2.properties_out[:].pressure\"\n",
    "\n",
    "df_meta['FG_PrSH_2_Mix_Fm'][\"reference_string\"] = \"m.fs.PrSH.side_2.properties_out[:].flow_mass\"\n",
    "df_meta['FG_PrSH_2_Mix_T'][\"reference_string\"] = \"m.fs.PrSH.side_2.properties_out[:].temperature\"\n",
    "df_meta['FG_PrSH_2_Mix_P'][\"reference_string\"] = \"m.fs.PrSH.side_2.properties_out[:].pressure\"\n",
    "\n",
    "df_meta['FG_2_ECON_Fm'][\"reference_string\"] = \"m.fs.ECON.side_2.properties_in[:].flow_mass\"\n",
    "df_meta['FG_2_ECON_T'][\"reference_string\"] = \"m.fs.ECON.side_2.properties_in[:].temperature\"\n",
    "df_meta['FG_2_ECON_P'][\"reference_string\"] = \"m.fs.ECON.side_2.properties_in[:].pressure\"\n",
    "\n",
    "df_meta['FG_2_AIRPH_Fm'][\"reference_string\"] = \"m.fs.ECON.side_2.properties_out[:].flow_mass\"\n",
    "df_meta['FG_2_AIRPH_T'][\"reference_string\"] = \"m.fs.ECON.side_2.properties_out[:].temperature\"\n",
    "df_meta['FG_2_AIRPH_P'][\"reference_string\"] = \"m.fs.ECON.side_2.properties_out[:].pressure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the model references to the tag metadata based on the strings above.\n",
    "da.upadate_metadata_model_references(m, df_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of data tags that we want to use for the data reconciliation problem.  \n",
    "# The key is the tag and the value is a reference to a quantity in the model.  \n",
    "data_tags = {k:v[\"reference\"][0] for k, v in df_meta.items() if v[\"reference\"] is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output from the data reconciliation step usually gives full stream information\n",
    "# for a flowsheet including quantities that are unmeasured. To use the results more easily, \n",
    "# it is good practice to map most of the data reconciliation results to flowsheet stream names.\n",
    "import idaes.core.util.tables as ta\n",
    "\n",
    "stream_dict = ta.arcs_to_stream_dict(\n",
    "    m, \n",
    "    additional={\n",
    "        'MS': m.fs.ATMP1.mixed_state,\n",
    "        'ATMP_In': m.fs.FSH.side_1.properties_out,\n",
    "        'FSH_In': m.fs.FSH.side_1.properties_in,\n",
    "        'PrSH_IN': m.fs.PrSH.side_1.properties_in,\n",
    "        'RHT_COLD': m.fs.RH.side_1.properties_in,\n",
    "        'RHT_HOT': m.fs.RH.side_1.properties_out,\n",
    "        'PlatenSH_IN': m.fs.PlSH.control_volume.properties_in,\n",
    "        'BFW': m.fs.ECON.side_1.properties_in,\n",
    "        'ECON_OUT': m.fs.ECON.side_1.properties_out,\n",
    "        'FG_2_FSH': m.fs.FSH.side_2.properties_in,\n",
    "    },\n",
    "    sort=True,\n",
    ")\n",
    "\n",
    "state_dict = ta.stream_states_dict(stream_dict, time_point=0)\n",
    "recon_tags = ta.tag_state_quantities(\n",
    "    blocks=state_dict, \n",
    "    attributes=(\n",
    "        \"flow_mass\", \n",
    "        \"flow_mol\", \n",
    "        \"enth_mol\", \n",
    "        \"temperature\", \n",
    "        \"pressure\", \n",
    "        (\"flow_mol_comp\", \"O2\"),\n",
    "        (\"flow_mol_comp\", \"NO\"),\n",
    "        (\"flow_mol_comp\", \"N2\"),\n",
    "        (\"flow_mol_comp\", \"SO2\"),\n",
    "        (\"flow_mol_comp\", \"CO2\"),\n",
    "        (\"flow_mol_comp\", \"H2O\"),\n",
    "    ), \n",
    "    labels=(\"_Fm\", \"_F\", \"_h\", \"_T\", \"_P\", \"_F[O2]\", \"_F[NO]\", \"_F[N2]\", \"_F[SO2]\", \"_F[CO2]\", \"_F[H2O]\"),\n",
    ")\n",
    "# add additional model variables\n",
    "recon_tags[\"coal_flow\"] = m.fs.coal_flow\n",
    "recon_tags[\"stoich_ratio\"] = m.fs.SR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. View Model Flowsheet\n",
    "\n",
    "Model results or other quantities can be added to a process flow diagram. The PFD was drawn beforehand and the model results are added to tagged locations on the PFD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idaes.core.util.misc import svg_tag  # utility to place numbers/text in an SVG\n",
    "\n",
    "with open(\"Boiler_scpc_PFD.svg\", \"r\") as f:\n",
    "    s = svg_tag(svg=f, tags={\"subtitle\":\"Initialized Model\"})\n",
    "    s = svg_tag(svg=s, tags=data_tags, outfile=\"boiler_scpc_init.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG, display\n",
    "\n",
    "display(SVG(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.  Write Objective\n",
    "\n",
    "Next we write the objective function and additional constraints for the data reconciliation problem.  The objective is\n",
    "\n",
    "$$\\min \\sum_i \\left(\\frac{x_{\\text{data}, i} - x_{\\text{model}, i}}{\\sigma_i} \\right)^2$$\n",
    "\n",
    "Where $i \\in \\{\\text{Measured Quantities}\\}$ and $\\sigma_i$ is the standard deviation of measurement i estimated by binning the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add model parameters to contain measured data.  These are mutable so we can set a specific \n",
    "# change to specific data points later.\n",
    "m.data = pyo.Param(data_tags, mutable=True, doc=\"Process data for a specific point in time.\")\n",
    "m.data_stdev = pyo.Param(data_tags, mutable=True, doc=\"Process data standard deviation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'set_data' function below takes data from the model DataFrame and updates the\n",
    "# model data parameters.\n",
    "# fix tags dictionary is used to fix model inputs to their values in the data set (for each data point)\n",
    "# in this case Boiler Feed Water = inlet to economizer and Reheater Cold = Reheater inlet\n",
    "def set_data(m, df, data_tags, index=None, indexindex=None):\n",
    "    if index is None:\n",
    "        index = df.index[indexindex]\n",
    "    m.bin_no = df.iloc[index][\"bin_no\"]\n",
    "    for t in data_tags:\n",
    "        m.data[t] = df.iloc[index][t]\n",
    "        m.data_stdev[t] = bin_stdev[m.bin_no][t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# So we have something reasonable to start, set the data attached to the model to the first \n",
    "# data point.\n",
    "set_data(m, df, data_tags, indexindex=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add an expression for error divided by the standard deviation, and use it to write the data reconciliation objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.tags_obj = [\n",
    "    'BFW_F', \n",
    "    'BFW_T', \n",
    "    'BFW_P',        \n",
    "    \"RHT_COLD_F\", \n",
    "    \"RHT_COLD_T\", \n",
    "    \"RHT_COLD_P\",\n",
    "    \"ECON_OUT_T\",\n",
    "    \"ECON_OUT_P\",\n",
    "    \"RHT_HOT_T\",\n",
    "    \"RHT_HOT_P\",\n",
    "    \"MS_T\", \n",
    "    \"MS_P\", \n",
    "    \"FG_2_ECON_P\",\n",
    "    \"FG_2_AIRPH_T\",\n",
    "    \"FG_2_AIRPH_P\",\n",
    "    \"FG_RH_2_Mix_T\",\n",
    "    \"FG_RH_2_Mix_P\",\n",
    "    \"FG_RH_2_Mix_Fm\",\n",
    "    \"FG_2_FSH_P\",\n",
    "    \"FG_2_FSH_T\",\n",
    "    \"FG_PrSH_2_Mix_T\",\n",
    "    \"FG_PrSH_2_Mix_P\",\n",
    "    \"FG_PrSH_2_Mix_Fm\",\n",
    "]\n",
    "\n",
    "@m.Expression(data_tags)\n",
    "def err(m, i):\n",
    "    return (m.data[i] - data_tags[i])/m.data_stdev[i]\n",
    "\n",
    "m.objective = pyo.Objective(expr=sum(m.err[t]**2 for t in m.tags_obj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Solve Optimization\n",
    "\n",
    "Now we need to solve the data reconciliation problem for every data point.  The important results are stored in two DataFrames ```df_result``` which contains results tagged based on model stream names to be used in the parameter estimation step and ```df_result_cmp``` which contains reconciled data based on the original measurement tags and can be used to compare the original measurements to the reconciled results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add constraints or fix variable bounds to ensure reasonable flowsheet performance (i.e. LMTD, negative pressure drop, etc.).\n",
    "# In this case, before solving the data reconciliation problem\n",
    "# unfix the coal flowarate, stoichiometric ratio, and split fraction (flue gas to Reheater)\n",
    "\n",
    "# Surrogate models have been trained using a rigorous boiler fire side model \n",
    "# with fixed wall temperature and variable fuel flowrate and stoichiometric ratio.\n",
    "m.fs.coal_flow.unfix()\n",
    "m.fs.coal_flow.setub(70.0)\n",
    "m.fs.coal_flow.setlb(30.0)\n",
    "m.fs.SR.unfix() # stoichiometric ratio \n",
    "m.fs.Spl1.split_fraction[0,'outlet_1'].unfix()\n",
    "\n",
    "# Surrogate models are used for Flue Gas Exit Temperature, flue gas component molar flowrate,\n",
    "# and heat duty to the platen superheater and water wall\n",
    "m.fs.FSH.side_2.properties_in[:].temperature.unfix()\n",
    "m.fs.FSH.side_2.properties_in[:].pressure.fix()\n",
    "m.fs.FSH.side_2.properties_in[0].temperature.setub(1800)\n",
    "m.fs.FSH.side_2.properties_in[0].temperature.setlb(1200)\n",
    "\n",
    "# unfix flowsheet inlets\n",
    "m.fs.ECON.side_1_inlet.unfix()\n",
    "m.fs.RH.side_1_inlet.unfix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = pyo.SolverFactory('ipopt')\n",
    "solver.options = {'tol': 1e-6,\n",
    "                   'halt_on_ampl_error': 'no',\n",
    "                   'max_iter': 250}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# add bin information to reconciliation results so it can be used in parameter estimation\n",
    "df_result = pd.DataFrame(columns=list(recon_tags.keys())+[\"termination\", \"bin_no\", \"bin_power\"], index=df.index)\n",
    "df_result_cmp = pd.DataFrame(columns=list(data_tags.keys())+[\"termination\"], index=df.index)\n",
    "\n",
    "for i in df.index:\n",
    "    set_data(m, df, data_tags, index=i)\n",
    "    try:\n",
    "        res = solver.solve(m)\n",
    "        tc = str(res.solver.termination_condition)\n",
    "        if tc != 'optimal':\n",
    "            ms.from_json(m, fname=\"optimal_run.json.gz\")\n",
    "            set_data(m, df, data_tags, index=i)\n",
    "            res = solver.solve(m)\n",
    "            tc = str(res.solver.termination_condition)\n",
    "    except:\n",
    "        tc = \"fail\"\n",
    "    df_result.iloc[i][\"termination\"] = tc\n",
    "    df_result.iloc[i][\"bin_no\"] = df.iloc[i][\"bin_no\"]\n",
    "    df_result.iloc[i][\"bin_power\"] = df.iloc[i][\"bin_power\"]\n",
    "    df_result_cmp.iloc[i][\"termination\"] = tc\n",
    "    for t in recon_tags:\n",
    "        df_result.iloc[i][t] = pyo.value(recon_tags[t])\n",
    "    for t in data_tags:\n",
    "        df_result_cmp.iloc[i][t] = pyo.value(data_tags[t])\n",
    "    print(f\"{i} -- {tc}, objective: {pyo.value(m.objective)}\")\n",
    "\n",
    "    # save first solution to be used as initial point\n",
    "    if i == 0:\n",
    "        ms.to_json(m, fname='optimal_run.json.gz')\n",
    "    \n",
    "    # break after 10 runs to keep the example short\n",
    "    if i > 10:\n",
    "        break\n",
    "    # to see the full results see file boiler_plant_recon.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the reconciled data to be used for parameter estimation\n",
    "df_result.to_csv(\"boiler_plant_recon_short.csv\")\n",
    "# a smaller subset of data points have been run to keep the simulation time short,\n",
    "# however the full set of results can be found in boiler_plant_recon.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert algorithm works fine\n",
    "assert df_result.iloc[1][\"termination\"] == \"optimal\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
