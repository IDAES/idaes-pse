{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Data Management Framework in IDAES to store data and parameters\n",
    "\n",
    "In the previous two notebooks, we saw how to use the `parmest` tool with IDAES models (unit models or the state block) to estimate the binary interaction parameters for the NRTL model with benzene and toluene as components. In this module, we will specifically see how to use the Data Management Framework (DMF) in IDAES that enables data provenance. Specifically, this module will demonstrate storing estimated parameters and also the associated datasets that were used in estimating those parameters. In this example, we will be using the `Parameter_estimation_NRTL_using_unit_model` notebook. \n",
    "\n",
    "We will complete the following tasks:\n",
    "* Split the dataset into two sub-datasets and use this to estimate the binary interaction parameters\n",
    "* Use DMF to store the estimated parameters with the data source that was used\n",
    "\n",
    "## Key links to documentation:\n",
    "* DMF - https://idaes-pse.readthedocs.io/en/stable/user_guide/components/dmf/index.html?highlight=dmf \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Inline Exercise:</b>\n",
    "import `ConcreteModel` from Pyomo, `FlowsheetBlock` and `Flash` from IDAES. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: import ConcreteModel from pyomo.environ\n",
    "from pyomo.environ import ConcreteModel, value\n",
    "\n",
    "# Todo: import FlowsheetBlock from idaes.core\n",
    "from idaes.core import FlowsheetBlock\n",
    "\n",
    "# Todo: import Flash unit model from idaes.generic_models.unit_models\n",
    "from idaes.generic_models.unit_models import Flash\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we will be importing the parameter block that we will be using in this module and the idaes logger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idaes.generic_models.properties.activity_coeff_models.\\\n",
    "    BTX_activity_coeff_VLE import BTXParameterBlock\n",
    "import idaes.logger as idaeslog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we import `parmest` from Pyomo and the `pandas` package. We need `pandas` as `parmest` uses `pandas.dataframe` for handling the input data and the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyomo.contrib.parmest.parmest as parmest\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up an initialized model\n",
    "\n",
    "We need to provide a method that returns an initialized model to the `parmest` tool in Pyomo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Inline Exercise:</b>\n",
    "Using what you have learned from previous modules, fill in the missing code below to return an initialized IDAES model. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NRTL_model(data):\n",
    "    \n",
    "    #Todo: Create a ConcreteModel object\n",
    "    m = ConcreteModel()\n",
    "    \n",
    "    #Todo: Create FlowsheetBlock object\n",
    "    m.fs = FlowsheetBlock(default={\"dynamic\": False})\n",
    "    \n",
    "\n",
    "    #Todo: Create a properties parameter object with the following options:\n",
    "    # \"valid_phase\": ('Liq', 'Vap')\n",
    "    # \"activity_coeff_model\": 'NRTL'\n",
    "    m.fs.properties = BTXParameterBlock(default={\"valid_phase\":\n",
    "                                                 ('Liq', 'Vap'),\n",
    "                                                 \"activity_coeff_model\":\n",
    "                                                 'NRTL'})\n",
    "    m.fs.flash = Flash(default={\"property_package\": m.fs.properties})\n",
    "\n",
    "    # Initialize at a certain inlet condition\n",
    "    m.fs.flash.inlet.flow_mol.fix(1)\n",
    "    m.fs.flash.inlet.temperature.fix(368)\n",
    "    m.fs.flash.inlet.pressure.fix(101325)\n",
    "    m.fs.flash.inlet.mole_frac_comp[0, \"benzene\"].fix(0.5)\n",
    "    m.fs.flash.inlet.mole_frac_comp[0, \"toluene\"].fix(0.5)\n",
    "\n",
    "    # Set Flash unit specifications\n",
    "    m.fs.flash.heat_duty.fix(0)\n",
    "    m.fs.flash.deltaP.fix(0)\n",
    "\n",
    "    # Fix NRTL specific variables\n",
    "    # alpha values (set at 0.3)\n",
    "    m.fs.properties.\\\n",
    "        alpha[\"benzene\", \"benzene\"].fix(0)\n",
    "    m.fs.properties.\\\n",
    "        alpha[\"benzene\", \"toluene\"].fix(0.3)\n",
    "    m.fs.properties.\\\n",
    "        alpha[\"toluene\", \"toluene\"].fix(0)\n",
    "    m.fs.properties.\\\n",
    "        alpha[\"toluene\", \"benzene\"].fix(0.3)\n",
    "\n",
    "    # initial tau values\n",
    "    m.fs.properties.\\\n",
    "        tau[\"benzene\", \"benzene\"].fix(0)\n",
    "    m.fs.properties.\\\n",
    "        tau[\"benzene\", \"toluene\"].fix(-0.9)\n",
    "    m.fs.properties.\\\n",
    "        tau[\"toluene\", \"toluene\"].fix(0)\n",
    "    m.fs.properties.\\\n",
    "        tau[\"toluene\", \"benzene\"].fix(1.4)\n",
    "\n",
    "    # Initialize the flash unit\n",
    "    m.fs.flash.initialize(outlvl=idaeslog.INFO_LOW)\n",
    "\n",
    "    # Fix at actual temperature\n",
    "    m.fs.flash.inlet.temperature.fix(float(data[\"temperature\"]))\n",
    "\n",
    "    # Set bounds on variables to be estimated\n",
    "    m.fs.properties.\\\n",
    "        tau[\"benzene\", \"toluene\"].setlb(-5)\n",
    "    m.fs.properties.\\\n",
    "        tau[\"benzene\", \"toluene\"].setub(5)\n",
    "\n",
    "    m.fs.properties.\\\n",
    "        tau[\"toluene\", \"benzene\"].setlb(-5)\n",
    "    m.fs.properties.\\\n",
    "        tau[\"toluene\", \"benzene\"].setub(5)\n",
    "\n",
    "    # Return initialized flash model\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter estimation using parmest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to providing a method to return an initialized model, the `parmest` tool needs the following:\n",
    "\n",
    "* List of variable names to be estimated\n",
    "* Dataset with multiple scenarios\n",
    "* Expression to compute the sum of squared errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we only estimate the binary interaction parameter (`tau_ij`). Given that this variable is usually indexed as `tau_ij = Var(component_list, component_list)`, there are 2*2=4 degrees of freedom. However, when i=j, the binary interaction parameter is 0. Therefore, in this problem, we estimate the binary interaction parameter for the following variables only:\n",
    "\n",
    "* fs.properties.tau['benzene', 'toluene']\n",
    "* fs.properties.tau['toluene', 'benzene']\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Inline Exercise:</b>\n",
    "Create a list called `variable_name` with the above-mentioned variables declared as strings.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Create a list of vars to estimate\n",
    "variable_name = [\"fs.properties.tau['benzene', 'toluene']\",\n",
    "                 \"fs.properties.tau['toluene', 'benzene']\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyomo's `parmest` tool supports the following data formats:\n",
    "- pandas dataframe\n",
    "- list of dictionaries\n",
    "- list of json file names.\n",
    "\n",
    "Please see the documentation for more details. \n",
    "\n",
    "For this example, we load data from the csv file `BT_NRTL_dataset.csv`. The dataset consists of fifty data points which provide the mole fraction of benzene in the vapor and liquid phase as a function of temperature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data from csv\n",
    "data = pd.read_csv('BT_NRTL_dataset.csv')\n",
    "\n",
    "# Display the dataset\n",
    "display(data)\n",
    "\n",
    "# Split the data set into two data sets\n",
    "data_subset_1 = data.loc[0:24]\n",
    "display(data_subset_1)\n",
    "\n",
    "data_subset_2 = data.loc[25:49].reset_index()\n",
    "display(data_subset_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up DMF\n",
    "* Perform imports\n",
    "* Create a new workspace in a temporary directory under `~/.idaes`. You can modify this path if you need to.\n",
    "* Set that workspace as the default to use for `%dmf` \"magics\" in this Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMF imports\n",
    "from pathlib import Path\n",
    "from idaes.dmf import DMF, magics\n",
    "from idaes.dmf.resource import Resource, create_relation, Predicates\n",
    "# use or create idaes \"dotfile\" in home directory\n",
    "wspath = Path(\"~/.idaes\").expanduser()\n",
    "if not wspath.exists():\n",
    "    wspath.mkdir()\n",
    "# use/create a subdirectory as a DMF workspace for the workshop\n",
    "wspath = wspath / \"workshop_workspace\"\n",
    "_dmf = DMF(path=wspath, create=not wspath.exists())\n",
    "\n",
    "%dmf init ~/.idaes/workshop_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show contents of DMF workspace\n",
    "This shows what is currently in the DMF workspace. If you ran this notebook earlier with the same workspace location,\n",
    "you will see the DMF resources you created at that time. Otherwise it will be empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show current contents of DMF workspace\n",
    "%dmf list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base dataset\n",
    "name = \"BT NRTL dataset\"\n",
    "ds_base = _dmf.find_one(name=name)\n",
    "if not ds_base:\n",
    "    ds_base = _dmf.new(file=\"BT_NRTL_dataset.csv\", name=name)\n",
    "    \n",
    "# Splits\n",
    "ds_splits, new_relations = [], False\n",
    "for i in (1, 2):\n",
    "    name = f'BT NRTL split{i}'\n",
    "    df = data_subset_1 if i == 1 else data_subset_2\n",
    "    df_file = f'BT_NRTL_dataset_split{i}.csv'\n",
    "    df.to_csv(df_file)\n",
    "    dss = _dmf.find_one(name=name)\n",
    "    if not dss:\n",
    "        dss = _dmf.new(file=df_file, name=name)\n",
    "        create_relation(dss, Predicates.derived, ds_base)\n",
    "        new_relations = True\n",
    "    ds_splits.append(dss)\n",
    "\n",
    "# Update if relations were added\n",
    "if new_relations:\n",
    "    _dmf.update()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List DMF objects\n",
    "Check if the raw data and splits are recorded in the DMF.\n",
    "Note that if you ran this notebook earlier, the estimated parameters will also be listed. This is a feature, not a bug!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dmf.resource_count\n",
    "%dmf list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to provide a method to return an expression to compute the sum of squared errors that will be used as the objective in solving the parameter estimation problem. For this problem, the error will be computed for the mole fraction of benzene in the vapor and liquid phase between the model prediction and data. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Inline Exercise:</b>\n",
    "Complete the following cell by adding an expression to compute the sum of square errors. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create method to return an expression that computes the sum of squared error\n",
    "def SSE(m, data):\n",
    "    expr = ((float(data[\"vap_benzene\"]) -\n",
    "             m.fs.flash.vap_outlet.mole_frac_comp[0, \"benzene\"])**2 +\n",
    "            (float(data[\"liq_benzene\"]) -\n",
    "             m.fs.flash.liq_outlet.mole_frac_comp[0, \"benzene\"])**2)\n",
    "    return expr*1E4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b>\n",
    "Notice that we have scaled the expression up by a factor of 10000 as the SSE computed here will be an extremely small number given that we are using the difference in mole fraction in our expression. A well-scaled objective will help improve solve robustness when using IPOPT. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to set up the parameter estimation problem. We will create a parameter estimation object called `pest`. As shown below, we pass the method that returns an initialized model, dataset, list of variable names to estimate, and the SSE expression to the Estimator object. `tee=True` will print the solver output after solving the parameter estimation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a parameter estimation object for data subset 1\n",
    "pest_data_subset_1 = parmest.Estimator(NRTL_model, data_subset_1, variable_name, SSE, tee=True)\n",
    "\n",
    "# Initialize a parameter estimation object for data subset 2\n",
    "pest_data_subset_2 = parmest.Estimator(NRTL_model, data_subset_2, variable_name, SSE, tee=True)\n",
    "\n",
    "# Run parameter estimation using data subset 1\n",
    "obj_value_1, parameters_1 = pest_data_subset_1.theta_est()\n",
    "\n",
    "# Run parameter estimation using data subset 2\n",
    "obj_value_2, parameters_2 = pest_data_subset_2.theta_est()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us display the results by running the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----Using Data Subset 1----\")\n",
    "print()\n",
    "print(\"The SSE at the optimal solution is %0.6f\" % (obj_value_1*1e-4))\n",
    "print()\n",
    "print(\"The values for the parameters are as follows:\")\n",
    "for k,v in parameters_1.items():\n",
    "    print(k, \"=\", v)\n",
    "\n",
    "print()\n",
    "print(\"----Using Data Subset 2----\")\n",
    "print()\n",
    "print(\"The SSE at the optimal solution is %0.6f\" % (obj_value_2*1e-4))\n",
    "print()\n",
    "print(\"The values for the parameters are as follows:\")\n",
    "for k,v in parameters_2.items():\n",
    "    print(k, \"=\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parameters_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_tau(d, chem1, chem2):\n",
    "    found_key = None\n",
    "    for key in d:\n",
    "        if re.match(fr\"fs\\.properties\\.tau.*{chem1}.*{chem2}.*\", key):\n",
    "            found_key = key\n",
    "            break\n",
    "    if found_key is None:\n",
    "        raise KeyError(f\"Did not find any key for fs.properties.tau with '{chem1}' followed by '{chem2}'\")\n",
    "    return d[found_key]\n",
    "\n",
    "# reformulate in simpler form using get_tau() function to be robust to formatting details of the keys\n",
    "# returned by theta_est() above.\n",
    "dmf_params = {}\n",
    "for n, p_n in ((1, parameters_1), (2, parameters_2)):\n",
    "    for chem1, chem2 in (('benzene', 'toluene'), ('toluene', 'benzene')):\n",
    "        dmf_params[f\"{n}:{chem1[0]}{chem2[0]}\"] = get_tau(p_n, chem1, chem2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save parameters in DMF\n",
    "The estimated parameters will be saved in the DMF and a \"relation\" will be recorded that remembers which data split\n",
    "each set of estimated parameters came from. When we're done the relations in the DMF will look like this:\n",
    "```\n",
    "BT NRTL dataset\n",
    "    │\n",
    "    ├───◀─┤derived│ BT NRTL split2 ◀─┤derived│ BT NRTL est param2\n",
    "    │\n",
    "    └───◀─┤derived│ BT NRTL split1 ◀─┤derived│ BT NRTL est param1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to DMF\n",
    "# create resources\n",
    "name = \"BT NRTL est param1\"\n",
    "ds_s1 = _dmf.find_one(name=name)\n",
    "if not ds_s1:\n",
    "    ds_s1 = _dmf.new(name=name, desc=\"Solution for data subset 1\", data={'SSE': obj_value_1, 'parameters': \n",
    "                                                                         {'tau': {'benzene,toluene': dmf_params[\"1:bt\"],\n",
    "                                                                                  'toluene,benzene': dmf_params[\"1:tb\"]}}})\n",
    "    create_relation(ds_s1, Predicates.derived, ds_splits[0])\n",
    "name = \"BT NRTL est param2\"\n",
    "ds_s2 = _dmf.find_one(name=name)\n",
    "if not ds_s2:\n",
    "    ds_s2 = _dmf.new(name=name, desc=\"Solution for data subset 2\", data={'SSE': obj_value_2, 'parameters': \n",
    "                                                                         {'tau': {'benzene,toluene': dmf_params[\"2:bt\"],\n",
    "                                                                                  'toluene,benzene': dmf_params[\"2:tb\"]}}})\n",
    "\n",
    "    create_relation(ds_s2, Predicates.derived, ds_splits[1])\n",
    "# save relations (prints number of objects processed)\n",
    "_dmf.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Estimated Parameters\n",
    "\n",
    "In the notebook [Flash Unit Model using NRTL](../ParamEst/DMF_2_flash_unit_Model_with_NRTL_solution.ipynb), we will see how the parameters that were estimated will be used to simulate a flash unit model with NRTL property package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
